# ğŸ˜ ELK Stack - Docker Compose Setup

Un environnement de dÃ©veloppement complet pour la stack ELK (Elasticsearch, Logstash, Kibana) avec une application de test intÃ©grÃ©e et des options de configuration flexibles.

## ğŸ—ï¸ Architecture du Projet

```
docker-elk/
â”œâ”€â”€ elk/                    # Stack ELK principal
â”‚   â”œâ”€â”€ elasticsearch/      # Configuration Elasticsearch
â”‚   â”œâ”€â”€ logstash/          # Configuration Logstash
â”‚   â”œâ”€â”€ kibana/            # Configuration Kibana
â”‚   â”œâ”€â”€ docker-compose.yml # Orchestration des services ELK
â”‚   â””â”€â”€ test_logs.py       # Script de test des logs
â”œâ”€â”€ test-app/              # Application de test avec sidecar
â”‚   â”œâ”€â”€ docker-compose.yml # Orchestration de l'app de test
â”‚   â”œâ”€â”€ filebeat-config/   # Configuration Filebeat
â”‚   â”œâ”€â”€ metricbeat-config/ # Configuration Metricbeat
â”‚   â””â”€â”€ logs/              # Volume partagÃ© des logs
â””â”€â”€ README.md              # Ce fichier
```

## ğŸš€ DÃ©marrage Rapide

### 1. Configuration Initiale d'Elasticsearch

```bash
# DÃ©marrer le service de configuration initiale
cd elk
docker-compose --profile=setup up -d setup
```

**âš ï¸ Important :** Ce service ne doit Ãªtre exÃ©cutÃ© qu'une seule fois lors de la premiÃ¨re initialisation. Il configure les utilisateurs et rÃ´les de base.

### 2. DÃ©marrage de la Stack ELK

```bash
# DÃ©marrer Elasticsearch, Logstash et Kibana
docker-compose up -d
```

### 3. AccÃ¨s Ã  Kibana

Ouvrez votre navigateur et allez sur : **https://localhost:5601**

## ğŸ§ª Application de Test

### DÃ©marrage de l'Application de Test

```bash
# Aller dans le rÃ©pertoire test-app
cd test-app

# DÃ©marrer l'application de test avec Filebeat
docker-compose up -d
```

L'application de test :
- ğŸ• GÃ©nÃ¨re des logs en continu avec la bonne timezone (Europe/Paris)
- ğŸ“ CrÃ©e des logs avec diffÃ©rents niveaux (INFO, DEBUG, WARN, ERROR)
- ğŸ”„ Met Ã  jour le fichier `logs/app.log` toutes les 3 secondes
- ğŸ³ Utilise un sidecar Filebeat pour collecter les logs

### Structure des Logs GÃ©nÃ©rÃ©s

```
2025-08-24 19:36:37: [INFO] Application de test dÃ©marrÃ©e
2025-08-24 19:36:37: [DEBUG] GÃ©nÃ©ration de logs de test
2025-08-24 19:36:37: [INFO] Test de performance en cours...
2025-08-24 19:36:37: [WARN] Attention: log de test
```

## ğŸ”§ Configuration

### Configuration Filebeat

Le sidecar Filebeat est configurÃ© pour :
- ğŸ“ Surveiller le rÃ©pertoire `/var/log/app/*.log`
- ğŸ·ï¸ Ajouter des champs personnalisÃ©s :
  - `app: "test-app"`
  - `environment: "development"`
  - `component: "application"`
  - `log_type: "app"`
- ğŸ“¤ Envoyer les logs vers Logstash sur le port 5044

### Configuration Logstash

Logstash traite les logs avec :
- ğŸ” **Parsing Grok** : Extraction des timestamps et niveaux de log
- ğŸ• **Conversion de timezone** : Support ISO8601
- ğŸ·ï¸ **Enrichissement** : Ajout de mÃ©tadonnÃ©es et champs personnalisÃ©s
- ğŸ¯ **Logique mÃ©tier** : Champs "babylove" basÃ©s sur le niveau de log
- ğŸ“Š **Sortie** : Indexation dans Elasticsearch + debug stdout

## ğŸ¯ Options de Configuration AvancÃ©es

### Alternative : Pipeline d'Ingestion Elasticsearch

Au lieu d'utiliser Logstash, vous pouvez configurer Filebeat pour envoyer directement vers Elasticsearch avec un pipeline d'ingestion personnalisÃ© :

1. **CrÃ©er le pipeline d'ingestion** :
   ```bash
   # Utiliser le fichier ingest-pipeline.http avec Postman
   # ou curl pour crÃ©er le pipeline dans Elasticsearch
   ```

2. **Modifier la configuration Filebeat** :
   ```yaml
   # Commenter la section Logstash
   # output.logstash:
   #   hosts: ["elk-logstash:5044"]

   # DÃ©commenter la section Elasticsearch
   output.elasticsearch:
     hosts: ["http://elasticsearch:9200"]
     username: "elastic"
     password: "changeme"
     ssl.verification_mode: none
     pipeline: "custom_timestamp_pipeline"
   ```

## ğŸ§ª Tests et Validation

### Test des Logs

```bash
# Tester l'envoi de logs via TCP vers Logstash
cd elk
python test_logs.py
```

### VÃ©rification des DonnÃ©es

```bash
# VÃ©rifier le nombre de documents indexÃ©s
curl "http://localhost:9200/logs-*/_count?pretty"

# Rechercher des logs spÃ©cifiques
curl "http://localhost:9200/logs-*/_search?q=app:test-app&pretty"
```

## ğŸŒ Ports et AccÃ¨s

| Service | Port | Description |
|---------|------|-------------|
| Elasticsearch | 9200 | API REST |
| Elasticsearch | 9300 | Transport |
| Logstash | 5044 | Beats Input |
| Logstash | 50000 | TCP Input |
| Logstash | 9600 | API HTTP |
| Kibana | 5601 | Interface Web |

## ğŸ” Monitoring et Debug

### Logs des Services

```bash
# Logs Logstash
docker-compose logs logstash

# Logs Filebeat
cd test-app
docker-compose logs filebeat-sidecar

# Logs de l'application de test
docker-compose logs test-app
```

### VÃ©rification de la ConnectivitÃ©

```bash
# Test de la connexion Elasticsearch
curl "http://localhost:9200/_cluster/health?pretty"

# Test de la connexion Kibana
curl "http://localhost:5601/api/status"
```

## ğŸš¨ DÃ©pannage

### ProblÃ¨mes Courants

1. **Filebeat ne peut pas se connecter Ã  Logstash** :
   - VÃ©rifier que les deux services utilisent le mÃªme rÃ©seau Docker
   - Utiliser `elk-logstash:5044` comme nom d'hÃ´te

2. **ProblÃ¨mes de timezone** :
   - VÃ©rifier la variable `TZ=Europe/Paris` dans docker-compose.yml
   - RedÃ©marrer les conteneurs aprÃ¨s modification

3. **Elasticsearch ne dÃ©marre pas** :
   - VÃ©rifier l'espace disque disponible
   - VÃ©rifier les permissions des volumes

## ğŸ“š Ressources

- [Documentation Elasticsearch](https://www.elastic.co/guide/index.html)
- [Documentation Logstash](https://www.elastic.co/guide/en/logstash/current/index.html)
- [Documentation Kibana](https://www.elastic.co/guide/en/kibana/current/index.html)
- [Documentation Filebeat](https://www.elastic.co/guide/en/beats/filebeat/current/index.html)

## ğŸ¤ Contribution

Ce projet est configurÃ© pour un environnement de dÃ©veloppement. Pour la production, assurez-vous de :
- ğŸ” Configurer la sÃ©curitÃ© Elasticsearch
- ğŸ“Š Ajuster les paramÃ¨tres de performance
- ğŸš€ Configurer la persistance des donnÃ©es
- ğŸ“ Documenter les procÃ©dures de sauvegarde

---

**Note** : Ce projet utilise Docker Compose pour la simplicitÃ©. Pour un environnement Podman, remplacez `docker-compose` par `podman-compose` dans toutes les commandes.
